<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Artificial Neural Network | namdarine </title> <meta name="author" content="Nam Gyu Lee"> <meta name="description" content="Concepts and understanding of Artificial Neural Network"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://namdarine.github.io/blog/2023/ANN/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> namdarine </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Artificial Neural Network</h1> <p class="post-meta"> October 17, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/wil"> <i class="fa-solid fa-hashtag fa-sm"></i> WIL</a>     ·   <a href="/blog/category/ai-ml"> <i class="fa-solid fa-tag fa-sm"></i> AI/ML</a>   <a href="/blog/category/data-mining"> <i class="fa-solid fa-tag fa-sm"></i> Data_Mining</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <blockquote> <p>A branch of machine learning models that are built using principles of neuronal organization discovered by connectionism in the biological neural networks constituting animal brains.</p> </blockquote> <p>An Artificial Neural Network (ANN) teaches computers to process data inspired by the human brain. It is a type of deep learning that uses nodes or neurons interconnected in a hierarchical structure similar to the human brain. Hidden layers are needed if the data must be separated using a <strong>non-linear</strong> boundary. Generalize the single neuron perceptron to a more complex architecture of nodes capable of learning nonlinear decision boundaries.</p> <h2 id="what-is-the-difference-between-ann-and-perceptron">What is the difference between ANN and Perceptron</h2> <p>The major difference is the inclusion of hidden layers. Perceptron can create only <mark>one</mark> hyperplane.</p> <h1 id="structure-of-ann">Structure of ANN</h1> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ANN/layer-480.webp 480w,/assets/img/ANN/layer-800.webp 800w,/assets/img/ANN/layer-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/ANN/layer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="three-kinds-of-neural-networks">Three kinds of neural networks</h2> <h3 id="1-feed-forward-neural-networks-ffnn">1. Feed Forward Neural Networks (FFNN)</h3> <p>General neural networks for classification, regression, etc.</p> <h3 id="2-convolutional-neural-networks">2. Convolutional neural networks</h3> <p>Excel at image recognition.</p> <h3 id="3-recurrent-neural-networks">3. Recurrent neural networks</h3> <p>Excel at language tasks.</p> <h2 id="hidden-layer">Hidden Layer</h2> <p>It can be viewed as learning potential representations or features that are useful to differentiate classes. Also, it dramatically improves their ability to represent arbitrarily complex decision boundaries. Hidden nodes learn potential representation features useful for class boundaries. The first hidden layer captures simpler features since it receives the predictors as input. Subsequent hidden layers hone specific patterns of the data to extract features.</p> <h1 id="activation-function">Activation Function</h1> <p>It provides non-linearity to an ANN and allows it to create non-linear class boundaries.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ANN/activation_function-480.webp 480w,/assets/img/ANN/activation_function-800.webp 800w,/assets/img/ANN/activation_function-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/ANN/activation_function.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <a href="https://www.v7labs.com/blog/neural-networks-activation-functions" rel="external nofollow noopener" target="_blank">V7 labs</a> </div> <h2 id="how-to-choose">How to choose?</h2> <p>Match the activation function at the output layer <u>based on the type of prediction problem</u>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Regression : Linear activation function.

	$$\sigma(z) = z$$

- Binary classification : Sigmoid / Logistic activation function.
	$$\begin{align} \sigma(z) &amp;= \frac{1}{1 + e^{-x}} \\ \sigma^{'}(z) &amp;= \sigma(z) \cdot (1 - \sigma(z)) \end{align}$$

- Multiclass classification : Softmax activation function.

	$$\sigma(z_i) = \frac{e^{z_i}}{\sum_{j = 1}^{k}{e^{z_j}}}, \;\; for \;\; i = 1, \cdots, k \;\; and \;\; z = (z_1, \cdots, z_k) \in R$$

- Multilabel classification : sigmoid activation function.

	$$\begin{align} \sigma(z) &amp;= \frac{1}{1 + e^{-z}} \\ \sigma^{'} &amp;= \sigma(z) \cdot (1 - \sigma(z)) \end{align}$$

- Convolutional Neural Network (CNN) : ReLU activation function.

	$$\begin{align} \sigma(z) &amp;= max(0, z) \\
	\sigma^{'}(z) &amp;= \begin{cases} 1, \;\; if \;\; z &gt; 0 \\ 0, \;\; if \;\; z ≤ 0 \end{cases} \end{align}$$

- Recurrent Neural Network : Tanh and/or Sigmoid activation function.

	$$\begin{align} \sigma(z) &amp;= \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} \\
	\sigma^{'}(z) &amp;= 1 - tanh^{2}(z) \end{align}$$
</code></pre></div></div> <p>For the hidden layers, start with <strong>ReLU</strong> activation function and move to others if results are sub-optimal.</p> <h2 id="example">Example</h2> <p>Use the sigmoid at the hidden layers and the output layer. \(\sigma(z) = \frac{1}{1 + e^{-z}}\)</p> <p>Loss : \(\frac{1}{2}\sum_{i = 1}^{n}{(\hat{y_i} - y_i)^2}\)</p> <ul> <li>Initialize \(\vec{w}\) <ul> <li> \[\vec{w} = N(0, \sigma^2)\] <ul> <li>if \(\sigma^2\) too small : the output will <strong>converge</strong> to 0</li> <li>if \(\sigma^2\) too large : the output will <strong>diverge</strong> </li> <li>Xavier initialization : \(\sigma^2 = \frac{2}{n_in + n_out}\)</li> <li>He initialization : \(\sigma^2 = \frac{2}{n_in}\)</li> </ul> </li> </ul> </li> </ul> <p>The network input to the neuron : \(z = w^Tx = \sum\_{i = 1}^{n}{w_i x_i} = w_1x_1 + \cdots + w_nx_n\)</p> <p>The output from the neuron : \(\sigma(w^Tx) = \sigma(z)\)</p> <h1 id="feed-forward-neural-network">Feed-Forward Neural Network</h1> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ANN/FFNN%20example-480.webp 480w,/assets/img/ANN/FFNN%20example-800.webp 800w,/assets/img/ANN/FFNN%20example-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/ANN/FFNN%20example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>X = [1, 4, 5], y = [0.1, 0.05]</p> <p>Input for \(h_1\) : \(z_{h1} = (x_1w_1 + x_2w_3 + x_3w_5) = (1\times0.1) + (4\times0.3) + (5\times0.5) = 3.8\)</p> <p>Output for \(h_1\) : \(\sigma(z_{h1}) = \sigma(3.8) = \frac{1}{1 + e^{-3.8}} = 0.98\)</p> <p>Input for \(h_2\) : \(z_{h2} = (x_1w_2 + x_2w_4 + x_3w_6) = (1\times0.2) + (4\times0.4) + (5\times0.6) = 4.8\)</p> <p>Output for \(h_2\) : \(\sigma(z_{h2}) = \sigma(4.8) = \frac{1}{1 + e^{-4.8}} = 0.99\)</p> <p>Input for \(o_1\) : \(z_{o1} = (\sigma(z_{h1})\times w_7 + \sigma(z_{h2})\times w_9) = (0.98\times0.7) + (0.99\times0.9) = 1.58\)</p> <p>Output for \(o_1\) : \(\sigma(z_{o1}) = \sigma(1.58) = \frac{1}{1 + e^{-1.58}} = 0.83\)</p> <p>Input for \(o_2\) : \(z_{o2} = (\sigma(z_{h1})\times w_8 + \sigma(z_{h2})\times w_{10}) = (0.98\times0.8) + (0.99\times0.1) = 0.88\)</p> <p>Output for \(o_2\) : \(\sigma(z_{o2}) = \sigma(0.88) = \frac{1}{1 + e^{-0.88}} = 0.71\)</p> <p>Loss: \(\frac{1}{2}[(\sigma(z_{o1}) - y_1)^2 + (\sigma(z_{o2}) - y_2)^2] = \frac{1}{2}[(0.83 - 0.1)^2 + (0.71 - 0.05)^2] = 0.48\)</p> <h1 id="backpropagation">Backpropagation</h1> <p>To reduce the loss / error use the Backpropagation method. The chain rule is used for the backpropagation. \(\begin{align} \frac{\partial E}{\partial w*7} &amp;= \frac{\partial E}{\partial \sigma(z*{o1})} \cdot \frac{\partial \sigma(z*{o1})}{\partial z*{o1}} \cdot \frac{\partial z*{o1}}{\partial w_7} \\ &amp;= [(\sigma(z*{o1}) - y*1)]\cdot [\sigma(z*{o1})(1 - \sigma(z*{o1}))]\cdot [\sigma(z*{h1})] \\ &amp;= [(0.83 - 0.1)]\cdot [(0.83 - (1 - 0.83)]\cdot [0.98] \\ &amp;= 0.10 \end{align}\) \(\frac{\partial E}{\partial w*1} = \frac{\partial E}{\partial \sigma(z*{h1})} \cdot \frac{\partial \sigma(z*{h1})}{\partial z*{h1}} \cdot \frac{\partial z\_{h1}}{\partial w_1}\)</p> <p><strong>Result</strong> A gradient vector of weights is used for updating the weights to get to the minimum gradient (Jacobian matrix). \(\nabla E = [\frac{\partial E}{\partial w_1}, \frac{\partial E}{\partial w_2}, \frac{\partial E}{\partial w_3}, \frac{\partial E}{\partial w_4}, \cdots, \frac{\partial E}{\partial w_n}]^T = [0.61, 0.87, 0.21, \cdots, 0.99]^T\) Update the weight with this gradient vector: $w_{new} = w_{old} - \eta \nabla E$</p> <h2 id="gradient-descent">Gradient descent</h2> <p>Use gradient descent algorithm for error (or cost) function minimization and to minimize the error function with respect to the weights. This algorithm is used in the training dataset to modify weights during each epoch to minimize the cost or error.</p> <h3 id="types">Types</h3> <ul> <li>Batch gradient descent : Calculate the error for each observation and perform the update $w$ by calculating the mean error at the end of the training data.</li> <li>Stochastic gradient descent : Calculate the error for each observation and update $w$.</li> <li>Mini-batch gradient descent - Preferred method <ul> <li>Divide the data into small batches, calculate the error for each placed observation, and perform the update $w$ by calculating the mean error at the end of the batch.</li> </ul> </li> </ul> <h1 id="reference">Reference</h1> <ul> <li>CS 422, Data Mining, prof. Vijay K. Gurbani, Fall 2023, Illinois Institute of Technology</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/ML-Final_Prep/">Machine Learning Final Preparation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Perceptron/">Artificial Neural Network - Perceptron</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/2025-03-19-ConvNeXt-V2-review/"></a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Binary-Search-Tree/">Binary Search Tree (BST)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Amortized-Analysis/">Amortized Analysis</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Nam Gyu Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>