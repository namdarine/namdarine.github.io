<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://namdarine.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://namdarine.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-10T12:48:30+00:00</updated><id>https://namdarine.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">IaaS vs PaaS vs SaaS</title><link href="https://namdarine.github.io/blog/2024/Cloud_computing/" rel="alternate" type="text/html" title="IaaS vs PaaS vs SaaS"/><published>2024-05-08T18:00:00+00:00</published><updated>2024-05-08T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2024/Cloud_computing</id><content type="html" xml:base="https://namdarine.github.io/blog/2024/Cloud_computing/"><![CDATA[<p>IaaS, PaaS, and SaaS are the three most popular types of cloud service offerings. They are sometimes referred to as cloud service models or cloud computing service models.</p> <h1 id="infrastructure-as-a-service">Infrastructure as a service</h1> <p>Also known as IaaS. It is on-demand access to cloud-hosted physical and virtual servers, storage, and networking - the backend IT infrastructure for running applications and workloads in the cloud. The difference is that the cloud service provider hosts, manages, and maintains the hardware and computing resources in its own data centers. IaaS customers use the hardware via an internet connection and pay for that use on a subscription or pay-as-you-go basis. Customers can provision, configure and operate the servers and infrastructure resources via a graphical dashboard, or programmatically through APIs.</p> <p>IaaS is like a Lego factory.</p> <h2 id="benefits">Benefits</h2> <ol> <li><strong>Flexibility</strong> : Compared to traditional IT, IaaS gives customers more <strong>flexibility</strong> to build out computing resources as needed and to scale them up or down in response to spikes or slow-downs in traffic.</li> <li><strong>Reduction of customer costs and overhead</strong> : It lets customers avoid the up-front expense and overhead of purchasing and maintaining its own on-premises data center.</li> <li><strong>Scalability</strong> : It eliminates the constant tradeoff between the waste of purchasing excess on-premises capacity to accommodate spikes, versus the poor performance or outages that can result from not having enough capacity for unanticipated traffic bursts or growth.</li> <li><strong>Higher availability</strong> : The company can effortlessly set up backup servers and even deploy them in different locations to guarantee continued operation in case of local power failures or physical disasters.</li> <li><strong>Lower latency, and improved performance</strong> : Because IaaS providers typically operate data centers in multiple geographies, IaaS customers can locate apps and services closer to users to minimize latency and maximize performance.</li> <li><strong>Improved responsiveness</strong> : Customers can quickly set up resources, try out new ideas rapidly, and easily introduce them to a larger audience.</li> <li><strong>Comprehensive security</strong> : With strong security measures in place at the office, data centers, and encryption, organizations can often benefit from enhanced security and protection similar to what they would have if they managed the cloud infrastructure themselves.</li> <li><strong>Faster access to best-of-breed technology</strong> : Cloud providers compete by offering cutting-edge technologies to their users. Customers using IaaS can benefit from these technologies much sooner and at a lower cost compared to implementing them in their own physical locations.</li> </ol> <h2 id="usage">Usage</h2> <ul> <li>Disaster recovery</li> <li>Ecommerce</li> <li>IoT, event processing, AI</li> <li>Startups</li> <li>Software development</li> </ul> <h1 id="platform-as-a-service">Platform as a service</h1> <p>As known as PaaS. It provides a cloud-based platform for developing, running, and managing applications. The cloud services provider hosts manages and maintains all the hardware and software included in the platform, servers, OS software, storage, networking, databases, middleware, runtimes, frameworks, and development tools. Also provide related services for security, OS and software upgrades, and backups.</p> <p>Users can access PaaS through GUI. Development or DevOps teams can collaborate on all their work across the entire application lifecycle, coding, integration, testing, delivery, deployment, and feedback.</p> <p>PaaS is like a Lego brick. PaaS developer provides the Lego bricks to the software developers and the software developers make their own Lego model using the bricks. They do not need to make their own Lego bricks for their service; they just choose the bricks and pay for them.</p> <h2 id="benefits-1">Benefits</h2> <ol> <li><strong>Efficiency</strong> : Allows customers to build, test, deploy run, update, and scale applications more quickly and cost-effectively than they might if they had to build out and manage their own on-premises platform.</li> <li><strong>Faster time to market</strong> : Development teams are able to spin-up development, testing, and production environments in minutes, rather than weeks or months using PaaS.</li> <li><strong>Low- to no-risk testing and adoption of new technologies</strong> : Typically, a PaaS platform has an application that includes access to a wide range of up-to-date resources above and below the stack. This enables enterprises to operate new OS without significant investment in systems, languages, and other tools. Users can test the infrastructure required to test or run their system, language, and other tools.</li> <li><strong>Simplified collaboration</strong> : As a cloud-based service, PaaS provides a shared software development environment, giving development and operations teams access to all the tools they need, from anywhere with an Internet Connection.</li> <li><strong>A more scalable approach</strong> : With PaaS, organizations can purchase extra capacity for building, testing, staging, and running applications whenever they need it.</li> <li><strong>Less to manage</strong> : PaaS offloads infrastructure management, patches, updates, and other administrative tasks to the cloud service provider.</li> </ol> <h2 id="usage-1">Usage</h2> <ul> <li>API development and management</li> <li>IoT</li> <li>Agile development and DevOps</li> <li>Cloud-native development and hybrid cloud strategy</li> </ul> <h1 id="software-as-a-service">Software as a service</h1> <p>As known as SaaS. It is cloud-hosted, ready-to-use application software. Users pay a monthly or annual fee to use a complete application from within a web browser, desktop client, or mobile app. The application and all of the infrastructure required to deliver it-servers, storage, networking, middleware, application software, data storage-are hosted and managed by the SaaS vendor. Simply, the user does not need to download the software to use.</p> <p>The vendor manages all upgrades and patches to the software. As part of the Service Level Agreements (SLAs), vendors ensure availability, performance, and security levels. Customers can add more users and data storage on demand by paying extra.</p> <p>Email, social media, and cloud file storage solutions are examples of SaaS applications. The chatGPT is SaaS product.</p> <p>SaaS is like already made the Lego model.</p> <h2 id="benefits-2">Benefits</h2> <ol> <li><strong>Convenience</strong> : SaaS offloads all infrastructure and application management to the SaaS vendor. All the user has to do is create an account, pay the fee, and start using the application. The vendor handles everything else, from maintaining the server hardware and software to managing user access and security, storing and managing data, implementing upgrades and patches, and more.</li> <li><strong>Minimal risk</strong> : There is a free trial period or low monthly fees provided by most SaaS providers. Let customers try the software to get used to it or see if it will meet their needs.</li> <li><strong>Anytime/anywhere productivity</strong> : If there is an internet connection, the customers can use SaaS products anytime and anywhere. Adding users is as simple as registering and paying for new seats - customers can purchase more data storage for a nominal charge.</li> </ol> <p>Some SaaS vendors allow the user to customize their product from provided a companion PaaS solution.</p>]]></content><author><name></name></author><category term="Cloud_Computing"/><category term="WIS"/><summary type="html"><![CDATA[Concepts and understanding of IaaS, PaaS, and SaaS]]></summary></entry><entry><title type="html">DBSCAN</title><link href="https://namdarine.github.io/blog/2024/DBSCAN/" rel="alternate" type="text/html" title="DBSCAN"/><published>2024-03-29T18:00:00+00:00</published><updated>2024-03-29T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2024/DBSCAN</id><content type="html" xml:base="https://namdarine.github.io/blog/2024/DBSCAN/"><![CDATA[<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/sample_DBSCAN.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="AI"/><category term="Data_Mining"/><category term="WIS"/><summary type="html"><![CDATA[Concepts and understanding of DBSCAN Function]]></summary></entry><entry><title type="html">Artificial Neural Network</title><link href="https://namdarine.github.io/blog/2023/ANN/" rel="alternate" type="text/html" title="Artificial Neural Network"/><published>2023-10-17T18:00:00+00:00</published><updated>2023-10-17T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/ANN</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/ANN/"><![CDATA[<h1 id="introduction">Introduction</h1> <blockquote> <p>A branch of machine learning models that are built using principles of neuronal organization discovered by connectionism in the biological neural networks constituting animal brains.</p> </blockquote> <p>An Artificial Neural Network (ANN) teaches computers to process data inspired by the human brain. It is a type of deep learning that uses nodes or neurons interconnected in a hierarchical structure similar to the human brain. Hidden layers are needed if the data must be separated using a <strong>non-linear</strong> boundary. Generalize the single neuron perceptron to a more complex architecture of nodes capable of learning nonlinear decision boundaries.</p> <h2 id="what-is-the-difference-between-ann-and-perceptron">What is the difference between ANN and Perceptron</h2> <p>The major difference is the inclusion of hidden layers. Perceptron can create only <mark>one</mark> hyperplane.</p> <h1 id="structure-of-ann">Structure of ANN</h1> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ANN/layer-480.webp 480w,/assets/img/ANN/layer-800.webp 800w,/assets/img/ANN/layer-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ANN/layer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="three-kinds-of-neural-networks">Three kinds of neural networks</h2> <h3 id="1-feed-forward-neural-networks-ffnn">1. Feed Forward Neural Networks (FFNN)</h3> <p>General neural networks for classification, regression, etc.</p> <h3 id="2-convolutional-neural-networks">2. Convolutional neural networks</h3> <p>Excel at image recognition.</p> <h3 id="3-recurrent-neural-networks">3. Recurrent neural networks</h3> <p>Excel at language tasks.</p> <h2 id="hidden-layer">Hidden Layer</h2> <p>It can be viewed as learning potential representations or features that are useful to differentiate classes. Also, it dramatically improves their ability to represent arbitrarily complex decision boundaries. Hidden nodes learn potential representation features useful for class boundaries. The first hidden layer captures simpler features since it receives the predictors as input. Subsequent hidden layers hone specific patterns of the data to extract features.</p> <h1 id="activation-function">Activation Function</h1> <p>It provides non-linearity to an ANN and allows it to create non-linear class boundaries.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ANN/activation_function-480.webp 480w,/assets/img/ANN/activation_function-800.webp 800w,/assets/img/ANN/activation_function-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ANN/activation_function.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> <a href="https://www.v7labs.com/blog/neural-networks-activation-functions">V7 labs</a> </div> <h2 id="how-to-choose">How to choose?</h2> <p>Match the activation function at the output layer <u>based on the type of prediction problem</u>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Regression : Linear activation function.

	$$\sigma(z) = z$$

- Binary classification : Sigmoid / Logistic activation function.
	$$\begin{align} \sigma(z) &amp;= \frac{1}{1 + e^{-x}} \\ \sigma^{'}(z) &amp;= \sigma(z) \cdot (1 - \sigma(z)) \end{align}$$

- Multiclass classification : Softmax activation function.

	$$\sigma(z_i) = \frac{e^{z_i}}{\sum_{j = 1}^{k}{e^{z_j}}}, \;\; for \;\; i = 1, \cdots, k \;\; and \;\; z = (z_1, \cdots, z_k) \in R$$
	
- Multilabel classification : sigmoid activation function.

	$$\begin{align} \sigma(z) &amp;= \frac{1}{1 + e^{-z}} \\ \sigma^{'} &amp;= \sigma(z) \cdot (1 - \sigma(z)) \end{align}$$
	
- Convolutional Neural Network (CNN) : ReLU activation function.

	$$\begin{align} \sigma(z) &amp;= max(0, z) \\
	\sigma^{'}(z) &amp;= \begin{cases} 1, \;\; if \;\; z &gt; 0 \\ 0, \;\; if \;\; z ≤ 0 \end{cases} \end{align}$$

- Recurrent Neural Network : Tanh and/or Sigmoid activation function.

	$$\begin{align} \sigma(z) &amp;= \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} \\ 
	\sigma^{'}(z) &amp;= 1 - tanh^{2}(z) \end{align}$$
</code></pre></div></div> <p>For the hidden layers, start with <strong>ReLU</strong> activation function and move to others if results are sub-optimal.</p> <h2 id="example">Example</h2> <p>Use the sigmoid at the hidden layers and the output layer. \(\sigma(z) = \frac{1}{1 + e^{-z}}\)</p> <p>Loss : \(\frac{1}{2}\sum_{i = 1}^{n}{(\hat{y_i} - y_i)^2}\)</p> <ul> <li>Initialize \(\vec{w}\) <ul> <li> \[\vec{w} = N(0, \sigma^2)\] <ul> <li>if \(\sigma^2\) too small : the output will <strong>converge</strong> to 0</li> <li>if \(\sigma^2\) too large : the output will <strong>diverge</strong></li> <li>Xavier initialization : \(\sigma^2 = \frac{2}{n_in + n_out}\)</li> <li>He initialization : \(\sigma^2 = \frac{2}{n_in}\)</li> </ul> </li> </ul> </li> </ul> <p>The network input to the neuron : \(z = w^Tx = \sum_{i = 1}^{n}{w_i x_i} = w_1x_1 + \cdots + w_nx_n\)</p> <p>The output from the neuron : \(\sigma(w^Tx) = \sigma(z)\)</p> <h1 id="feed-forward-neural-network">Feed-Forward Neural Network</h1> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ANN/FFNN%20example-480.webp 480w,/assets/img/ANN/FFNN%20example-800.webp 800w,/assets/img/ANN/FFNN%20example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ANN/FFNN%20example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>X = [1, 4, 5], y = [0.1, 0.05]</p> <p>Input for \(h_1\) : \(z_{h1} = (x_1w_1 + x_2w_3 + x_3w_5) = (1\times0.1) + (4\times0.3) + (5\times0.5) = 3.8\)</p> <p>Output for \(h_1\) : \(\sigma(z_{h1}) = \sigma(3.8) = \frac{1}{1 + e^{-3.8}} = 0.98\)</p> <p>Input for \(h_2\) : \(z_{h2} = (x_1w_2 + x_2w_4 + x_3w_6) = (1\times0.2) + (4\times0.4) + (5\times0.6) = 4.8\)</p> <p>Output for \(h_2\) : \(\sigma(z_{h2}) = \sigma(4.8) = \frac{1}{1 + e^{-4.8}} = 0.99\)</p> <p>Input for \(o_1\) : \(z_{o1} = (\sigma(z_{h1})\times w_7 + \sigma(z_{h2})\times w_9) = (0.98\times0.7) + (0.99\times0.9) = 1.58\)</p> <p>Output for \(o_1\) : \(\sigma(z_{o1}) = \sigma(1.58) = \frac{1}{1 + e^{-1.58}} = 0.83\)</p> <p>Input for \(o_2\) : \(z_{o2} = (\sigma(z_{h1})\times w_8 + \sigma(z_{h2})\times w_{10}) = (0.98\times0.8) + (0.99\times0.1) = 0.88\)</p> <p>Output for \(o_2\) : \(\sigma(z_{o2}) = \sigma(0.88) = \frac{1}{1 + e^{-0.88}} = 0.71\)</p> <p>Loss: \(\frac{1}{2}[(\sigma(z_{o1}) - y_1)^2 + (\sigma(z_{o2}) - y_2)^2] = \frac{1}{2}[(0.83 - 0.1)^2 + (0.71 - 0.05)^2] = 0.48\)</p> <h1 id="backpropagation">Backpropagation</h1> <p>To reduce the loss / error use the Backpropagation method. The chain rule is used for the backpropagation. \(\begin{align} \frac{\partial E}{\partial w_7} &amp;= \frac{\partial E}{\partial \sigma(z_{o1})} \cdot \frac{\partial \sigma(z_{o1})}{\partial z_{o1}} \cdot \frac{\partial z_{o1}}{\partial w_7} \\ &amp;= [(\sigma(z_{o1}) - y_1)]\cdot [\sigma(z_{o1})(1 - \sigma(z_{o1}))]\cdot [\sigma(z_{h1})] \\ &amp;= [(0.83 - 0.1)]\cdot [(0.83 - (1 - 0.83)]\cdot [0.98] \\ &amp;= 0.10 \end{align}\) \(\frac{\partial E}{\partial w_1} = \frac{\partial E}{\partial \sigma(z_{h1})} \cdot \frac{\partial \sigma(z_{h1})}{\partial z_{h1}} \cdot \frac{\partial z_{h1}}{\partial w_1}\)</p> <p><strong>Result</strong> A gradient vector of weights is used for updating the weights to get to the minimum gradient (Jacobian matrix). \(\nabla E = [\frac{\partial E}{\partial w_1}, \frac{\partial E}{\partial w_2}, \frac{\partial E}{\partial w_3}, \frac{\partial E}{\partial w_4}, \cdots, \frac{\partial E}{\partial w_n}]^T = [0.61, 0.87, 0.21, \cdots, 0.99]^T\) Update the weight with this gradient vector: $w_{new} = w_{old} - \eta \nabla E$</p> <h2 id="gradient-descent">Gradient descent</h2> <p>Use gradient descent algorithm for error (or cost) function minimization and to minimize the error function with respect to the weights. This algorithm is used in the training dataset to modify weights during each epoch to minimize the cost or error.</p> <h3 id="types">Types</h3> <ul> <li>Batch gradient descent : Calculate the error for each observation and perform the update $w$ by calculating the mean error at the end of the training data.</li> <li>Stochastic gradient descent : Calculate the error for each observation and update $w$.</li> <li>Mini-batch gradient descent - Preferred method <ul> <li>Divide the data into small batches, calculate the error for each placed observation, and perform the update $w$ by calculating the mean error at the end of the batch.</li> </ul> </li> </ul> <h1 id="reference">Reference</h1> <ul> <li>CS 422, Data Mining, prof. Vijay K. Gurbani, Fall 2023, Illinois Institute of Technology</li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="Data_Mining"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of Artificial Neural Network]]></summary></entry><entry><title type="html">Artificial Neural Network - Perceptron</title><link href="https://namdarine.github.io/blog/2023/Perceptron/" rel="alternate" type="text/html" title="Artificial Neural Network - Perceptron"/><published>2023-10-07T18:00:00+00:00</published><updated>2023-10-07T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/Perceptron</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/Perceptron/"><![CDATA[<p>The perceptron was investigated in 1957 by Frank Rosenblatt at Cornell. It was the first learning algorithm based on the concept of a neural network.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Perceptron/neuron_anatomy-480.webp 480w,/assets/img/Perceptron/neuron_anatomy-800.webp 800w,/assets/img/Perceptron/neuron_anatomy-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Perceptron/neuron_anatomy.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The perceptron was guaranteed to find the linear boundary between two classes if there is a boundary. The perceptron is a simple <strong>one-cell</strong>, most simplest, neural network. It is characterized as a <strong>feed-forward</strong> neural network that solves linearly separable problems. -&gt; If the data is linearly separable, the perceptron will find the hyperplane that separates it.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Perceptron/linear_seperable-480.webp 480w,/assets/img/Perceptron/linear_seperable-800.webp 800w,/assets/img/Perceptron/linear_seperable-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Perceptron/linear_seperable.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>More complex neural networks can solve data mining or learning tasks more effectively by gathering several perceptrons. They work together to solve the task.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Perceptron/diagram-480.webp 480w,/assets/img/Perceptron/diagram-800.webp 800w,/assets/img/Perceptron/diagram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Perceptron/diagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We can train a model to derive a hyperplane that will separate the classes, but there are two conditions. i) Dealing with a binary classification problem such as \(y_i \in \{-1, +1\}\) ii) Data is linearly separable.</p> <p>Training is all about adjusting the weight parameter, <em>w</em>, until the response predicted by the perceptron becomes consistent with the true response.</p> <p>However, even for binary classes, the perceptron cannot recognize the XOR function. To solve this, we need the multiple perceptron model. This is a general neural network.</p> <h2 id="example">Example</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Perceptron/perceptron_example-480.webp 480w,/assets/img/Perceptron/perceptron_example-800.webp 800w,/assets/img/Perceptron/perceptron_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Perceptron/perceptron_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In this case, 0.3 is weight, and 0.4 is bias. We can write it as a formula, \(\hat{y} = \begin{cases} 1: 0.3x_1 + 0.3x_2 + 0.3x_3 + 0.4 \ge 0 \\ -1: 0.3x_1 + 0.3x_2 + 0.3x_3 + 0.4 &lt; 0 \end{cases}\) This could be rewritten as \(\begin{align} \hat{y} &amp;= sign((\sum_{i=i}^{n}{w_i x_i}) + b) \\ &amp;= sign (\sum_{i = 0}^{n} {w_i \times x_i}) \\ &amp;= sign(w_i \cdot x_i) \end{align}\)</p> <p>Note: \(sign(x) := \begin{cases} -1 \;\;\; if \;\; x &lt; 0, \\ 0 \;\;\;\;\;\; if \;\; x = 0, \\ 1 \;\;\;\;\;\; if \;\; x &gt; 0 \end{cases}\)</p> <h1 id="reference">Reference</h1> <ul> <li>CS 422, Data Mining, prof. Vijay K. Gurbani, Fall 2023, Illinois Institute of Technology</li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="Data_Mining"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of Perceptron]]></summary></entry><entry><title type="html">What is GPT?</title><link href="https://namdarine.github.io/blog/2023/GPT/" rel="alternate" type="text/html" title="What is GPT?"/><published>2023-08-30T18:00:00+00:00</published><updated>2023-08-30T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/GPT</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/GPT/"><![CDATA[<blockquote> <p>GPT is Generative pre-trained transformers. It is a type of large language model and a prominent framework for generative artificial intelligence.</p> </blockquote> <p>There are two ways that AI develops a language model. The first is to use a person’s language as a statistic. The second is to use a neural network. Using the neural network is better performance. Google also uses this method on its search engine to predict what the user is about to search for.</p> <p>GPT is a conditional probability prediction tool underlying natural language processing. The difference between human beings and GPT is a vast amount of learning. When human beings write an article or essay, we write and fix and repeat it until we think it is done or perfect. However, GPT is not doing the same process as we do. When a user types the keywords, GPT gathers every data related to the keywords and makes the text article what the user asked.</p> <p>GPT models are based on transformer architecture. The concept of transformer architecture was first introduced in the report ‘Attention is all you need’ published by Google Brain in 2017. After that, the competition began to build a supermodel capable of handling various language tasks, Google’s BERT, MS’s Turing NLG, and OpenAI’s GPT3. Then which generation of GPT is used for ChatGPT is GPT 3.5. Because of this vast amount of train, developments in GPT language models have had a significant impact on natural language processing and other applications that rely on text data.</p> <h1 id="history-of-gpt">History of GPT</h1> <p>OpenAI introduced the first GPT in the world in 2018. The amount of the first GPT was trained with 117 million parameters. A year later, in 2019, the second GPT was released to the public by OpenAI. At this time, it was trained with 1.5 billion which is 10 times larger. The second GPT could write a page of the book in 10 seconds. In 2020, there was an upgraded version, GPT 3. It was trained with 175 billion parameters. What we can do with the third GPT is various language-related problem-solving, random writing, simple rule calculation, translation, and simple coding according to a given sentence.</p> <h2 id="before-gpt">Before GPT</h2> <p>Before transformer architecture technology was introduced, ‘generative pretraining’ was a long-established concept in machine learning applications. The most effective neural models for Natural Language Processing (NLP) typically utilize supervised learning using extensive volumes of data that have been labeled manually.</p> <h1 id="limitations">Limitations</h1> <ol> <li> <p><strong>Pre-training</strong> : It should be pre-trained. This is the major difference between human beings and GPT. When we have a conversation with others, we remember what we talked about previously, such as an hour or a week ago, but GPT does not. GPT does not have an ongoing long-term memory that learns from each interaction.</p> </li> <li> <p><strong>Limited input size</strong> : A user cannot provide a lot of text as input for the output. GPT3 has a prompt limit of about 2,048 tokens. It means that, for example, we cannot ask for translation over what it can handle.</p> </li> <li> <p><strong>Slow inference time</strong> : GPT3 has a slow inference time because the model takes a long time to generate results.</p> </li> <li> <p><strong>Lack of explainability</strong> : GPT3 is prone to the same problems that many neural networks face. Lack of ability to explain and interpret why certain inputs result in certain outputs. It does not understand the nuance contained in the sentence or words, such as anger, happy, or delight.</p> </li> </ol> <h1 id="risks">Risks</h1> <ol> <li><strong>Mimicry</strong> : NLP models like GPT3 are continuously improving in accuracy, blurring the line between machine-generated content and human-written text, leading to challenges in distinguishing between them. This could potentially give rise to concerns related to copyright infringement and plagiarism.</li> <li><strong>Accuracy</strong> : Even though GPT3 excels at mimicking the structure of text produced by humans, it faces difficulties in maintaining factual precision across various use cases.</li> <li><strong>Bias</strong> : Language models carry a susceptibility to biases inherent in machine learning. These models are trained on internet text, they have the potential to internalize and reflect the biases prevalent in human online interactions. For instance, a pair of researchers at the Middlebury Institute of International Studies at Monterey discovered that GPT2 is proficient at producing extremist content, such as dialogues resembling those of conspiracy theorists and white supremacists. This situation opens the door to the automation and amplification of hate speech, often unintentionally. To address this concern, ChatGPT, built upon a version of GPT3, strives to mitigate such risks through more extensive training and incorporation of user input. There was this issue previously with the chatbot from MS.</li> </ol> <h1 id="problem">Problem</h1> <p>Ethics issues always come up when the latest technologies related to artificial intelligence are introduced every time, such as generating fake news, deep fake, and other misleading forms of content.</p> <p>We should establish related organizations and make related regulations globally before the technology develops further.</p> <h1 id="reference">Reference</h1> <ul> <li> <p>Network, A. (2021, February 19). <em>GPT 모델의 발전 과정 그리고 한계</em>. Medium. <a href="https://medium.com/ai-networkkr/gpt-%EB%AA%A8%EB%8D%B8%EC%9D%98-%EB%B0%9C%EC%A0%84-%EA%B3%BC%EC%A0%95-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%ED%95%9C%EA%B3%84-81cea353200c">Medium </a></p> </li> <li> <p>Wikimedia Foundation. (2023, August 13). <em>Generative pre-trained transformer</em>. Wikipedia. <a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer#:~:text=The%20first%20GPT%20was%20introduced,generate%20novel%20human%2Dlike%20content.">Wikipedia </a></p> </li> <li> <p>Lutkevich, B., &amp; Schmelzer, R. (2023, August 17). <em>What is GPT-3? everything you need to know - techtarget</em>. Enterprise AI. <a href="https://www.techtarget.com/searchenterpriseai/definition/GPT-3">techtarget</a></p> </li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="WIS"/><summary type="html"><![CDATA[Concepts and understanding of GPT]]></summary></entry><entry><title type="html">pandas.iloc vs pandas.loc</title><link href="https://namdarine.github.io/blog/2023/pandas.iloc-vs-pandas.loc/" rel="alternate" type="text/html" title="pandas.iloc vs pandas.loc"/><published>2023-07-18T18:00:00+00:00</published><updated>2023-07-18T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/pandas.iloc-vs-pandas.loc</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/pandas.iloc-vs-pandas.loc/"><![CDATA[<h1 id="dataframeloc-vs-dataframeiloc">DataFrame.loc vs DataFrame.iloc</h1> <h1 id="dataframeloc">DataFrame.loc</h1> <blockquote> <p>Access a group of rows and columns by <strong>label</strong>(s) or boolean array. <code class="language-plaintext highlighter-rouge">.loc[]</code> is primarily label based, but may also be used with a boolean array</p> </blockquote> <p>Select rows and columns by <strong>labels</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div></div> <h2 id="inputs">Inputs</h2> <ul> <li>A single label (e.g. <code class="language-plaintext highlighter-rouge">5</code> or <code class="language-plaintext highlighter-rouge">'a'</code> ) <ul> <li>Note, <strong>Never</strong> as an integer position along the index</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div> </div> </li> <li> <p>A list or array of labels (e.g. <code class="language-plaintext highlighter-rouge">['a', 'b', 'c']</code>)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">points</span><span class="sh">'</span><span class="p">]]</span>
</code></pre></div> </div> <ul> <li>Note, <code class="language-plaintext highlighter-rouge">df.loc[['a', 'b']]</code> ≠ <code class="language-plaintext highlighter-rouge">df.loc['a', 'b']</code> <ul> <li><code class="language-plaintext highlighter-rouge">df.loc['a', 'b']</code> → ‘a’: row, ‘b’: column</li> <li><code class="language-plaintext highlighter-rouge">df.loc[['a', 'b']]</code> → <code class="language-plaintext highlighter-rouge">['a', 'b']</code> is list of labels.</li> </ul> </li> </ul> </li> <li>A slice object with labels (e.g. <code class="language-plaintext highlighter-rouge">'a':'f'</code>) <ul> <li>Note, contrary to usual Python slices, both the start and the stop are included.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div> </div> </li> <li> <p>A boolean array of the same length as the axis being sliced (e.g. <code class="language-plaintext highlighter-rouge">[True, False, True]</code>)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">True</span><span class="p">]]</span>
</code></pre></div> </div> </li> <li> <p>An alignable boolean Series. The index of the key will be aligned before masking</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">([</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">],</span> 
  			<span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">points</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])]</span>
</code></pre></div> </div> </li> <li>An alignable index. The index of the returned selection will be the input.</li> <li> <p>A <code class="language-plaintext highlighter-rouge">callable</code> function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">points</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">30</span><span class="p">]</span>
</code></pre></div> </div> </li> <li> <p>Conditional</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">points</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">]</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">points</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]]</span>
</code></pre></div> </div> </li> </ul> <p>Also, can set value for all items matching the list of labels</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Italy</span>
</code></pre></div></div> <p>Or, set value for an entire row or column</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">40</span>
</code></pre></div></div> <h2 id="error">Error</h2> <ul> <li>KeyError: if any items are not found</li> <li>IndexingError: if an indexed key is passed and its index is unalignable to the frame index</li> </ul> <h1 id="dataframeiloc">DataFrame.iloc</h1> <blockquote> <p>Purely integer-location based indexing for selection by position. <code class="language-plaintext highlighter-rouge">.iloc[]</code> is primarily integer position based (from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">length-1</code> of the axis), but may also be used with a boolean array.</p> </blockquote> <p>Select rows and columns by index</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="p">]</span>
</code></pre></div></div> <h2 id="inputs-1">Inputs</h2> <ul> <li> <p>An integer</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div> </div> </li> <li> <p>A list or array of integers</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</code></pre></div> </div> </li> <li> <p>A slice object with ints</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span>
</code></pre></div> </div> </li> <li> <p>A boolean array</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]]</span>
</code></pre></div> </div> </li> <li> <p>A <code class="language-plaintext highlighter-rouge">callable</code> function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above). This is useful in method chains, when do not have a reference to calling object, but would like to base your selection on some value.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="n">index</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
  <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
</code></pre></div> </div> <ul> <li>The <em>x</em> passed to the <code class="language-plaintext highlighter-rouge">lambda</code> is the DataFrame being sliced. This selects the rows whose index label even.</li> </ul> </li> <li> <p>A tuple of row and column indexes. The tuple elements consist of one of the above inputs</p> </li> </ul> <h2 id="error-1">Error</h2> <ul> <li>IndexError: if a requested indexer is out of bounds, except slice indexers which allow out of bounds indexing</li> </ul> <h1 id="reference">Reference</h1> <ul> <li><em>pandas.DataFrame.iloc — pandas 2.0.3 documentation</em>. (n.d.). <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html">document</a></li> <li><em>pandas.DataFrame.loc — pandas 2.0.3 documentation</em>. (n.d.). <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc">document</a></li> </ul>]]></content><author><name></name></author><category term="Python"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of pandas.iloc and pandas.loc]]></summary></entry><entry><title type="html">Dynamic Table</title><link href="https://namdarine.github.io/blog/2023/Dynamic-Table/" rel="alternate" type="text/html" title="Dynamic Table"/><published>2023-03-29T18:00:00+00:00</published><updated>2023-03-29T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/Dynamic-Table</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/Dynamic-Table/"><![CDATA[<blockquote> <p>A dynamic table <em>T</em> is an array with changeable length. When the array is full, we increase its length; when the array is “Too empty”, we reduce its length.</p> </blockquote> <p>The claim that hash tables give have \(O(1)\) performance for lookup and the insert is based on the assumption that the number of elements stored in the table is comparable to the number of buckets. If a hash table has many more elements than buckets, the number of elements stored in each bucket will become large. 불필요한 사용을 막는다.</p> <h4 id="attributes">Attributes</h4> <ul> <li><em>T.table</em> : the array itself</li> <li><em>T.size</em> : length of the array</li> <li><em>T.num</em> : number of elements in <em>T</em> Start with \(T.size = 0\) and \(T.num = 0\)</li> </ul> <h1 id="insertion">Insertion</h1> <p>Start with \(T.table\) being empty. When inserting into an empty table, expand \(T.table\) so that \(T.size = 1\), then insert the element. Later, whenever need to insert an element into a full table, (\(T.size = T.num\)), expand \(T.table\) so that \(T.size\) is doubled. To double the size of $T.table$, claim a <u>new empty array of doubled size</u>, and move all the elements into the new array.</p> <h2 id="aggregate-analysis">Aggregate analysis</h2> <p>Let \(c_i\) be the actual cost of the \(i^{th}\) insertion. If \(T.table\) still have available slots while the \(i^{th}\) insertion, then \(c_i = 1\); if \(T.table\) is full while the \(i^{th}\) insertion and \(T.size = m\), then \(c_i = m + 1\). If there are <em>n</em> insertions, the total cost of <em>n</em> operations is below. -Note: do not consider the following. - There is only one table expansion, and \(T.size = m &gt;&gt; n\). In this case, there are not enough operations to be an amortized analysis. - Thus, assume that during all <em>n</em> insertions, \(T.size = m\) can be at most \(O(n)\). With the note above, can see that <em>n</em> operations have a total cost \(O(n^2)\), but this upper bound is not tight.</p> <h3 id="total-cost-of-n-insertions">Total cost of <em>n</em> insertions</h3> <p>There are two parts. One is i) <strong><em>n</em> simple insertions</strong> and ii) <strong>some table expansions</strong>.</p> <h4 id="i-n-simple-insertions">i) <em>n</em> simple insertions</h4> <p> It needs <em>n</em> times.</p> <h4 id="ii-some-table-expansions">ii) Some table expansions</h4> <p><strong>Assume that we have a worst-case.</strong> Start \(T.table\) being full and \(T.size = m\) So we start with a table expansion immediately and have a table expansion in the last insertion. A table expansion immediately takes \(m\) time then after another \(m\) insertions we need another table expansion that takes \(2m\) time. After another \(2m\) insertions we need another table expansion that takes \(4m\) time, and so on. In the end, after another \(2^km\) time. \(n = 1 + m + 2m + \cdots + 2^km\), and the total cost of table expansion is \(m + 2m + 4m + \cdots + 2^{k+1}m\). \(m + 2m + 4m + \cdots + 2^{k+1}m = (m - 2) + (2 + 2m + 4m+ \cdots + 2^{k+1}m)\) \(= (m -2) + 2n\) Thus, the total cost of \(n\) insertions are at most <strong>\((m - 2) + 2n + n = 3n + m -2\)</strong>. \(m = O(n)\), so the total cost is \(O(n)\).</p> <p>When \(m = 0\) (start with \(T.size = 0\)) or when $n$ is large enough (\(n &gt;&gt; m\)), have this total cost equals \(3n\). Thus, the amortized cost for insertion is \(\frac{3n}{n} = 3\).</p> <h2 id="accounting-method">Accounting Method</h2> <p>Whenever we do a simple insertion, we put two extra coins on that spot. When the array is full, \(T.num = T.size = 2m\), each of the \(m\) spots contain 2 coins, so we can use these \(2m\) coins to move all \(2m\) elements into a new table of size \(4m\) for free. Thus, the amortized cost for insertion is 3.</p> <h2 id="potential-method">Potential Method</h2> <p>Define \(\Phi(T) = 2T.num - T.size\) <br/> -&gt; <strong>always non-negative</strong></p> <p><mark>At first $$T.num = T.size = 0$$. After any number of insertions, we always have $$T.table$$ is at least **half full** so $$2\cdot T.num \ge T.size$$ is always true. </mark></p> <p>Let \(T_i\) be the dynamic table after the \(i^{th}\) insertion and simplify \(\Phi(T_i)\) as \(\Phi_i\).</p> <h4 id="c_i-is-simple-insertion">\(c_i\) is simple insertion</h4> <p>\(\hat {c_i} = c_i + \Phi_i - \Phi_{i-1}\) \(= 1 + (2\cdot T_i.num - T_i.size) - (2\cdot T_{i-1}.num - T_{i-1}.size)\) \(= 1 + 2\cdot (T-i.num - T_{i-1}.num) + (T_{i-1}.size - T_i.size)\) \(= 1 + 2\cdot 1 + 0\) \(= 3\)</p> <h4 id="c_i-is-insertion-with-expansion">\(c_i\) is insertion with expansion</h4> <p>\(\hat{c_i} = c_i + \Phi_i - \Phi_{i-1}\) \(= (T_{i-1}.num + 1) + (2\cdot T_i.num - T_i.size) - (2\cdot T_{i-1}.num - T_{i-1}.size)\)</p> <p>Let \(T_{i-1}.num = m\), then \(T_{i-1}.size = m, T_i.size = 2m, T_i.num = m + 1\) : \(\hat{c_i} = (m + 1) + (2\cdot(m + 1) - 2m) - (2\cdot m - m)\) \(= (m + 1) + 2 - m\) \(= 3\)</p> <h1 id="insertion-and-deletion">Insertion and Deletion</h1> <h4 id="what-about-we-contract-the-table-so-that-tsize-is-halved-whenever-we-delete-from-a-half-full-table">What about we contract the table so that \(T.size\) is halved whenever we delete from a half-full table?</h4> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Dynamic_Table-480.webp 480w,/assets/img/Dynamic_Table-800.webp 800w,/assets/img/Dynamic_Table-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Dynamic_Table.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>If we contract whenever it is half-full, we can have a series of operations that half of them with \(\Theta (n)\) time, and the total cost will be \(\Theta(n^2)\), making the amortized cost of each operation \(\Theta(n)\).</p> <p>Change the contraction strategy to whenever delete from a 1/4 full table, contract the table so that \(T.size\) is halved. Then we need a new potential function, since \(T\) can be less than half-full and \(\Phi(T) = 2\cdot T.num - T.size\) can be less than 0.</p> <p>Let \(\alpha(T) = \frac{T.num}{T.size}\) represents how full \(T.table\) is. When \(T.num = T.size = 0\), define \(\alpha(T) = 1\). The following is a new potential function: \(\Phi(T) =\) \(\begin{cases} 2\cdot T.num - T.size, \; if\; \alpha(T) \ge \frac{1}{2} \\ \frac {T.size}{2} - T.num, \; if\; \alpha(T) &lt; \frac{1}{2} \end{cases}\)</p> <p>With this new potential function, let us analyze a sequence of \(n\) insertion and deletion operations.</p> <h2 id="consider-the-case-that-the-ith-operation-is-an-insertion">Consider the case that the \(i^{th}\) operation is an <u>insertion</u></h2> <p>There are <strong>two</strong> cases.</p> <h3 id="when-alphat_i-1--frac12-and-">When \(\alpha(T_{i-1}) &lt; \frac{1}{2}\) and …</h3> <p>any insertion won’t trigger a table expansion.</p> <h4 id="if-alpha-t_i--frac12">if \(\alpha T(_i) &lt; \frac{1}{2})\)</h4> \[\begin{aligned}\hat{c_i} &amp;= c_i + \Phi_i - \Phi_{i-1}\\ &amp;= 1 + (\frac{T_i.size}{2} - T_i.num) - (\frac{T_{i-1}.size}{2} - T_{i-1}.num)\\ &amp;= 1 + (\frac{T_i.size}{2} - \frac{T_{i-1}.size}{2}) + (T_{i-1}.num - T_i.num)\\ &amp;= 1 + 0 + (-1) = 0 \end{aligned}\] <h4 id="but-alpha-t_i-ge-frac12">but \(\alpha (T_i) \ge \frac{1}{2}\)</h4> \[\begin{aligned} \hat{c_i} &amp;= c_i + \Phi_i - \Phi_{i-1}\\ &amp;= 1 + (2\cdot T_i.num - T_i.size) - (\frac{T_{i-1}.size}{2} - T_{i-1}.num)\\ &amp;= 1 + (2\cdot (T_{i-1}.num + 1) - T_{i-1}.size) - (\frac{T_{i-1}.size}{2} - T_{i-1}.num)\\ &amp;= 3\cdot T_{i-1}.num - \frac{3}{2}T_{i-1}.size) + 3\\ &amp;= 3\cdot \alpha(T_{i-1})\cdot T_{i-1}.size -\frac{3}{2}T_{i-1}.size + 3\\ &amp;&lt; \frac{3}{2}T_{i-1}.size - \frac{3}{2}T_{i-1}.size + 3\\ &amp; = 3 \end{aligned}\] <h2 id="consider-the-case-that-the-ith-operation-is-deletion">Consider the case that the $i^{th}$ operation is <u>deletion</u></h2> <p>There are <strong>four</strong> cases.</p> <h3 id="when-alphat_i-1-ge-frac12">When \(\alpha(T_{i-1}) \ge \frac{1}{2}\)</h3> <h4 id="and-alphat_i-ge-frac12">and \(\alpha(T_i) \ge \frac{1}{2}\)</h4> <p>-&gt; Before and after deletion, the table is at least half full.</p> \[\begin{aligned} \hat{c_i} &amp;= c_i + \Phi_i - \Phi_{i-1}\\ &amp;= 1 + (2\cdot T_i.num - T_i.size) - (2\cdot T_{i-1}.num - T_{i-1}.size)\\ &amp;= 1 + 2\cdot (T_i.num - T_{i-1}.num) + (T_{i-1}.size - T_i.size)\\ &amp;= 1 + (-2) + 0 = -1 \end{aligned}\] <h4 id="but-alphat_i--frac12">but \(\alpha(T_i) &lt; \frac{1}{2}\)</h4> <p>-&gt; Before deletion, the table was at least half full and after deletion, the table is less than half.</p> \[\begin{aligned} \hat{c_i} &amp;= c_i + \Phi_i - \Phi_{i-1}\\ &amp;= 1 + (\frac{T_i.size}{2} - T_i.num) - (2\cdot T_{i-1}.num - T_{i-1}.size)\\ &amp;= 1 + (\frac{T_{i-1}.size}{2} - (T_{i-1}.num -1)) - (2\cdot T_{i-1}.num - T_{i-1}.size)\\ &amp;= -3T_{i-1}.num + \frac{3}{2}T_{i-1}.size + 2\\ &amp;= -3\cdot \alpha(T_{i-1})\cdot T_{i-1}.size + \frac{3}{2} T_{i-1}.size + 2\\ &amp;\le -\frac{3}{2}T_{i-1}.size + \frac{3}{2}T_{i-1}.size + 2\\ &amp;= 2 \end{aligned}\] <h3 id="when-alpha-t_i-1--frac12">When \(\alpha (T_{i-1}) &lt; \frac{1}{2}\)</h3> <h4 id="simple-deletion">Simple deletion</h4> \[\begin{aligned} \hat{c_i} &amp;= c_i + \Phi_i - \Phi_{i-1}\\ &amp;= 1 + (\frac{T_i.size}{2} - T_i.num) - (\frac{T_{i-1}.size}{2} - T_{i-1}.num)\\ &amp;= 1 + (\frac{T_i.size}{2} - \frac{T_{i-1}.size}{2}) + (T_{i-1}.num - T_i.num)\\ &amp;= 1 + 0 + 1 = 2 \end{aligned}\] <h4 id="deletion-with-table-contraction">deletion with <u>table contraction</u></h4> <p>\(\begin{aligned} \hat{c_i} &amp;= c_i + \Phi_i - \Phi_{i-1}\\ &amp;= (1 + T_i.num) + (\frac{T_i.size}{2} - T_i.num) - (\frac{T_{i-1}.size}{2} - T_{i-1}.num) \end{aligned}\) Let $T_i.num = m - 1$, then $T_i.size = 2m, T_{i-1}.size = 4m, T_{i-1}.num = m$ \(\begin{aligned} \hat{c_i} &amp;= (1 + m -1) + (m - m + 1) - (2m - m)\\ &amp;= m + 1 = 1 \end{aligned}\)</p> <h1 id="reference">Reference</h1> <ul> <li>CS 430, Introduction to Algorithm, prof. Wang, Xiaolang, Spring 2023, Illinois Institute of Technology</li> </ul>]]></content><author><name></name></author><category term="Algorithm"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of Dynamic Table]]></summary></entry><entry><title type="html">Amortized Analysis</title><link href="https://namdarine.github.io/blog/2023/Amortized-Analysis/" rel="alternate" type="text/html" title="Amortized Analysis"/><published>2023-03-23T18:00:00+00:00</published><updated>2023-03-23T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/Amortized-Analysis</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/Amortized-Analysis/"><![CDATA[<blockquote> <p>Amortized analysis analyzes the costs associated with a data structure that averages the worst operations out over time.</p> </blockquote> <p>A data structure has one particularly costly operation, but it doesn’t get performed very often. That data structure shouldn’t be labeled costly just because that one operation, which is seldom performed, is costly. So, amortized analysis is used to <strong>average out the costly operations in the worst case.</strong> The worst-case scenario for a data structure is the absolute worst ordering of operations from a cost perspective. Once that ordering is found, then the operations can be averaged.</p> <p>=&gt; Refers to determining the time-averaged running time for a sequence operation, not an individual. It is different from average case analysis because we don’t assume that the data is arranged in an <u>average fashion</u>, not very bad, as we do for average case analysis for quick-sort. It applies to the method that consists of the sequence of operations, where a vast majority of operations are cheap but some of the operations are expensive.</p> <p><mark>The amortized analysis gives us the average performance of a series of operations in the worst case. It is useful when an operation or a set of operations occur successively, but only very a few of them have a bad complexity.</mark></p> <p>Three main types of amortized analysis - Aggregate analysis : Calculate the total cost of <em>n</em> operations first - Accounting method : save coins to a “virtual bank” when an operation is “cheap”, and we use the saved coins to pay for an “expansive” operation. - Potential method</p> <h1 id="increment-in-a-binary-counter">Increment in a binary counter</h1> <p>Given a (<em>k</em>-bit) binary counter <em>A</em>, we can see the time complexity of an <strong>Increment(<em>A</em>)</strong> is the number of flips to increase the counter value by 1. For example, in this binary counter, the cost to increment from 7 to 8 is 4, since we need to flip 4 digits. In general, it is easy to see that <strong>Increment(<em>A</em>)</strong> has worst-case time complexity <em>k</em>, since we might need to flip all digits in one incrementing.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Amortized_Analysis-480.webp 480w,/assets/img/Amortized_Analysis-800.webp 800w,/assets/img/Amortized_Analysis-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Amortized_Analysis.png" class="img-fluid rounded z-depth-1" width="400" height="600" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="the-amortized-cost-of-incrementa">The amortized cost of <strong>Increment(<em>A</em>)</strong></h2> <h3 id="aggregate-analysis">Aggregate analysis</h3> <p>On the right-hand side of the counter in the above image, we can see that after 16 calls, the total cost of <strong>Increment(<em>A</em>)</strong> is 31, we can guess that the amortized cost of <strong>Increment(<em>A</em>)</strong> is \(\frac{31}{16} \approx 2\), which is a constant and independent from <em>k</em></p> <p>A common example is a modified <u>stack</u>.</p> <h4 id="observation">Observation</h4> <p>The least significant bit flips in every increment, the second least significant bit flips in every two increments, and the third insignificant bit flips in every four increments… If there are <em>m</em> <strong>Increment(<em>A</em>)</strong> operations, the total running time is : \(m + \frac {m}{2} + \frac {m}{4} + \cdots = 2m\). Thus, the amortized cost of <strong>Increment(<em>A</em>)</strong> is \(\frac {2m}{m} = 2\).</p> <h3 id="accounting-method">Accounting method</h3> <blockquote> <p>Accounting method is aptly named because it borrows ideas and terms from accounting.</p> </blockquote> <p>Each operation is assigned a charge, called the amortized cost. Some operations can be charged more or less than they actually cost. If an operation’s amortized cost exceeds its actual cost, we assign the difference, called a credit, to specific objects in the data structure. Credit can be used later to help pay for other operations whose amortized cost is less than their actual cost. Credit can never be negative in any sequence of operations. The amortized cost of an operation is split between an operation’s actual cost and credit that is either deposited or used up. Each operation can have a different amortized cost, unlike aggregate analysis. Choosing the amortized cost for each operation is important, <u>but the costs must always be the same for a given operation no matter what the sequence of operations, just like for any method of amortized analysis.</u></p> <p>Assume that each flip is worth 1 coin (1 operation), but we pay one extra coin (and save the coin on that digit) when flipping a digit from 0 to 1. We use that saved coin to flip that digit from 1 back to 0 later.</p> <h4 id="observation-1">Observation</h4> <p>In each <strong>Increment(<em>A</em>)</strong> operation, we flip exactly one digit from 0 to 1. Whenever we need to flip a digit from 0 at the \(q^{th}\) insignificant digit to 1, we need to flip all the q - 1 insignificant digits from 1 to 0.</p> <p>Thus, an <strong>Increment(<em>A</em>)</strong> operation that the \(q^{th}\) insignificant digit from 0 to 1 has amortized cost: \(2 + 0 \times (q - 1) = 2\).</p> <h3 id="potential-method">Potential method</h3> <p>The potential method is similar to the accounting method. However, instead of thinking about the analysis in terms of cost and credit, the potential method thinks of work already done as potential energy that can pay for later operations. This is similar to how rolling a rock up a hill creates potential energy that then can bring it back down the hill with no effort. Unlike the accounting method, however, potential energy is associated with the data structure as a whole, not with individual operations.</p> <p>A potential function \(\Phi\) is defined on a data structure or a system, it describes the “potential energy” stored (or “money” saved) in a system or a data structure. For the same system, the potential function \(\Phi\) can be defined in many ways, but we require that <strong>\(\Phi\) needs to be non-negative</strong> after each operation. It’s like a debit card, sometimes you need to use your savings, but you are not allowed to have a negative amount of money in the account.</p> <p>For \(i = 1, 2, \cdots\) let \(c_i\) be the actual cost of the \(i^{th}\) operation in a series, let \(\hat{c_i}\) be the amortized cost of the \(i^{th}\) operation, let \(D_i\) be the system after the \(i^{th}\) operation and \(\Phi(D_i)\) be the potential in the system after the \(i^{th}\) operation,</p> <p>                \(\hat{c_i} = c_i + \Phi(D_i) - \Phi(D_{i-1}) = c_i + \Delta(\Phi(D_i))\)</p> <p>=&gt; The amortized cost of the \(i^{th}\) operation equals to the actual cost of theat operation plus the change that operation makes in the potential.</p> <p>It is not always easy to find a useful potential function, but in general we want the potential to increase a little after a “cheap” operation and the potential drops a lot after an “expansive” operation.</p> <p>For binary counter, can define \(\Phi\) as “number of 1’s on the binary counter”, and use \(A_i\) to represent the binary counter after the \(i^{th}\) <strong>Increment(<em>A</em>)</strong> operation. <strong>Increment(<em>A</em>)</strong> operation which flips the \(q^{th}\) insignificant digit from 0 to 1 has amortized cost:</p> <p>                            \(\hat{c_i} = c_i + \Phi(A_i) - \Phi(A_{i-1}) = c_i + \Delta(\Phi(A_i))\)</p> <p>                                \(= q + (1 - (q - 1))\)</p> <p>                                \(= 2\)</p> <p>Using different potential functions on the same system will give you different amortized costs. If the function didn’t give you an amortized cost as you expected, it means this potential function is not useful for this system, and it doesn’t mean all other potential functions cannot give you the expected amortized cost.</p> <h4 id="prove">Prove</h4> <p><strong>A typical way to do this is to define \(\Phi(D_0) = 0\) and show that \(\Phi(D_i) \ge 0\).</strong> =&gt; The \(i^{th}\) operation will have a potential difference of \(\Phi(D_i) - \Phi(D_{i-1})\). If this value is positive, then the amortized cost $a_i$ is an overcharge for this operation, and the potential energy of the data structure will increase. If it is negative, it is an undercharge, and the potential energy of the data structure will decrease. At the binary counter. The potential function chosen will simply be the number of operations on the binary counter. Therefore, before the sequence of operations begins, \(\Phi(D_0) = 0\) because there are no operations in the binary counter. For all future operations, it’s clear that \(\Phi(D_i) \ge 0\) because there cannot be a negative number of operations in the binary counter. Calculating the potential difference for an <strong><em>Increment(A)</em></strong> operation, we find that \(\Phi(D_i) - \Phi(D_{i-1}) = (size + 1) - size = 1\) So, the amortized cost of the <strong><em>Increment(A)</em></strong> is \(a_i = c_i + \Phi(D_i) - \Phi(D_{i-1}) = 1 + 1 = 2\) All of these operations have an amortized cost of \(O(1)\), so any sequence of operations of length <em>n</em> will take <em>O(n)</em> time. Since it was proven that \(\Phi(D_i) \ge \Phi(D_0)\) for all \(i\), this is a true upper bound. The worst case of \(n\) operations are therefore \(O(n)\).</p> <h2 id="example">Example</h2> <p>We’ve seen that A[1] is flipped \(\frac{n}{2}\) times and that A[2] is flipped \(\frac{n}{4}\) times. For an A of length <em>k</em>, how many bits are flipped for <em>n</em> increment operations? What does this mean for aggregate analysis? <br/> -&gt; For each A[i] where \(i\) is \({0, 1, \cdots, k-1}\), bit \(i\) is flipped \(\frac{n}{2^i}\). The summation is then \(\Sigma_{i = 0}^{k-1} {\frac{n}{2^i}} &lt; n\Sigma_{i=0}^{\infty} {\frac{1}{2^i}} = 2n\). So, there are 2n flips and this takes \(O(n)\) times. Using aggregate analysis \(\frac{T(n)}{n} = \frac{O(n)}{n} = O(1)\).</p> <p><strong>Suppose we wish not only to increment value in a 𝑘-digit binary counter 𝐴, but also to reset the value in 𝐴 to 0. Counting the cost of each flip as 1, can you implement Increment(𝐴) and Reset(𝐴) such that any sequence of 𝑚 Increment(𝐴) and Reset(𝐴) operations cost 𝑂(𝑚)? In other words, each operation in the sequence has amortized cost 𝑂(1), which is a constant and independent from 𝑘. If you can, show how; if you think it is impossible, show why.</strong></p> <p>=&gt; Yes, it is possible. It uses a binary representation of <em>A</em> as an array of <em>k</em> bits. Increment(A) operation is performed as starting from the least significant bit, flip the first 0 bit encountered to 1 and if 1 bit is flipped to 0, repeat the previous step for the next bit until 0 bit is flipped to 1 or the most significant bit is reached. Each bit flip in an Increment(A) operation costs 1. However, the number of bits that need to be flipped is at most <em>k,</em> which is constant. Thus, the amortized cost of an Increment(A) operation is O(1). The Reset(A) operation is performed by setting all bits to 0. It costs <em>k</em> flips, which is also a constant. Therefore, the amortized cost of a Reset(A) operation is O(1). The Increment(A) operation flips a maximum of <em>k</em> bits and the Reset(A) operation flips <em>k</em> bits. Therefore, any sequence of <em>m</em> operations a <em>A</em> has an O(m) cost in total, which means that the amortized cost of each operation in the sequence is O(1).</p> <h1 id="reference">Reference</h1> <ul> <li>CS 430, Introduction to Algorithm, prof. Wang, Xiaolang, Spring 2023, Illinois Institute of Technology</li> <li>Amortized analysis. Brilliant Math &amp; Science Wiki. (n.d.). <a href="https://brilliant.org/wiki/amortized-analysis/">brilliant.org/wiki/amortized-analysis</a></li> </ul>]]></content><author><name></name></author><category term="Algorithm"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of Amortized Analysis]]></summary></entry><entry><title type="html">Growth of Function - Big O</title><link href="https://namdarine.github.io/blog/2023/Growth-of-Function/" rel="alternate" type="text/html" title="Growth of Function - Big O"/><published>2023-01-28T18:00:00+00:00</published><updated>2023-01-28T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/Growth-of-Function</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/Growth-of-Function/"><![CDATA[<p>There exists a relation between the input data size (\(n\)) and the number of operations performed (\(N\)) with respect to time. This relation is denoted as the Order of growth in time complexity and given notation \(O(n)\) where ‘\(O\)’ is the order of growth and \(n\) is the length of the input. It is called <strong>Big O Notation</strong>. Big O notation expresses the run time of an algorithm in terms of how quickly it grows relative to the input \(n\) by defining the $N$ number of operations that are done on it. Also, the time complexity of an algorithm is denoted by the comvination of all \(O(n)\) assigned for each line of function. Big O notation is the prevalent notation to represent algorithmic complexity. It gives an <strong>upper bound</strong> on complexity and hence it signifies the worst-case performance of the algorithm. With such a notation, it’s easy to compare different algorithms because the notation tells clearly how the algorithm scales when input size increases. This is often called the <strong>order of growth</strong>.</p> <blockquote> <p>Let \(f\) and \(g\) be functions from the set of integers or the set of real numbers to the set of real numbers We say that \(f(x)\) is \(O(g(x))\) if there exist positive constants \(C\) and \(k\) such that: <br/>              \(|f(x)| \leq C|g(x)|\) <br/> whenever \(x &gt; k\). This is read as “\(f(x)\) is <strong>big-oh of</strong> \(g(x)\).”</p> </blockquote> <p>In other words, when \(x\) is large enough, \(f(x)\) is upper bounded by a constant time of \(g(x)\). Big-O notation is also called the <strong>asymptotic upper bound</strong> of a function. If a function is \(O(n)\), it is automatically \(O(n^2)\).</p> <p>The following graph is the example for Big-O.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Big_O_graph-480.webp 480w,/assets/img/Big_O_graph-800.webp 800w,/assets/img/Big_O_graph-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Big_O_graph.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h1 id="types-of-time-complexity">Types of Time Complexity</h1> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Big_O_chart-480.webp 480w,/assets/img/Big_O_chart-800.webp 800w,/assets/img/Big_O_chart-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Big_O_chart.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="o1---constant-time">\(O(1)\) - Constant time</h2> <p>When an algorithm is not dependent on the input size $n$. If an algorithm’s time complexity is constant, it means that it will always run in the same amount of time, no matter the input size.</p> <h3 id="example">Example</h3> <ul> <li>If we want to get the first item of an array, it does not matter how big the input size is. It always takes the same amount of time to find the first element in the array.</li> <li>Find if a number is odd or even</li> <li>Check if an item on an array is null</li> <li>Print the first element from a list</li> <li>Find a value on a map</li> </ul> <h2 id="on---linear-time">\(O(n)\) - Linear time</h2> <p>When the running time increases linearly with the length of the input, an algorithm is a linear time complexity. When the function involves checking all the values in input data, with \(O(n)\).</p> <h3 id="example-1">Example</h3> <ul> <li>Get the max/min value in an array</li> <li>Find a given element in a collection</li> <li>Print all the values in a list</li> </ul> <h2 id="olog-n---logarithmic-time">\(O(log n)\) - Logarithmic time</h2> <p>When an algorithm reduces the size of the input data in each step. This indicates that the number of operations is not the same as the input size. The number of operations gets reduced as the input size increases. This time complexities usually apply to algorithms that divide problems in half every time.</p> <h3 id="example-2">Example</h3> <ul> <li>Finding element on sorted array with binary search</li> </ul> <h2 id="on2---quadratic-time">\(O(n^2)\) - Quadratic time</h2> <p>An algorithm is said to have a non-linear time complexity where the running time increases non-linearly with the length of the input. Nested loops come under this order where one loop takes \(O(n)\) and if the function involves a loop within a loop, then it goes for \(O(n) \times O(n) = O(n^2)\) order.</p> <h3 id="example-3">Example</h3> <ul> <li>Check if a collection has duplicated values</li> <li>Sorting items in a collection using <strong>bubble sort, insertion sort, or selection sort</strong>.</li> <li>Find all possible ordered pairs in a array.</li> </ul> <h2 id="o2n">\(O(2^n)\)</h2> <p>Growth doubles with each addition to the input data set. The growth curve of an \(O(2^n)\) function is exponential - starting off very shallow, then rising meteorically. \(O(2^n)\) complexities are often seen in recursive functions that make 2 recursive calls and pass in the problem size of \(n - 1\).</p> <h3 id="example-4">Example</h3> <ul> <li>The recursive calculation of Fibonacci numbers.</li> <li>Tower of Hanoi</li> </ul> <h2 id="compare">Compare</h2> <p>\(O(1) &lt; O(log n) &lt; O(\sqrt n) &lt; O(n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) &lt; O(10^n) &lt; O(n!)\)</p> <h3 id="example-5">Example</h3> <ol> <li> <p>Show that \(f(n) = 4n^2 - 4\) is \(O(n^2)\). <br/>   -&gt;  can choose \(k = 1\) and \(C = 4\) (there are infinite choices of \(k\) and \(C\)). When \(n &gt; 1\), we have \(4n^2 -4 \le 4n^2\).</p> </li> <li> <p>Show that \(f(n) = 4n^2 - 4\) is not \(O(n)\). <br/>   -&gt; Prove by contradiction. If \(4n^2 - 4\) is \(O(n)\), then there exist positive constants \(k\) and \(C\) such that “if \(n &gt; k\), then \(4n^2 - 4 \le Cn\). When \(n &gt; 0\), we can divide both sides of the inequality by \(n\) and we get: \(4n - \frac {4}{n} \le C\), which implies that \(4n \le C + \frac {4}{n} &lt; C + 4\). Since \(C + 4\) is a constant, \(4n &lt; C + 4\) cannot hold for all \(n &gt; k\). In particular, if \(n &gt; max\){\(k, \frac{C+4}{4}\)}, it is not true that \(4n &lt; C + 4\). This contradiction shows that $n^2$ is not \(O(n)\).</p> </li> </ol> <h2 id="complexity-chart">Complexity Chart</h2> <h3 id="data-structure">Data Structure</h3> <table> <thead> <tr> <th style="text-align: center">Data<br/>Structures</th> <th style="text-align: center">Space Complexity</th> <th style="text-align: center">Average Case<br/>Time Complexity</th> <th style="text-align: center"> </th> <th style="text-align: center"> </th> </tr> </thead> <tbody> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td style="text-align: center">Access</td> <td style="text-align: center">Search</td> <td style="text-align: center">Insertion</td> </tr> <tr> <td style="text-align: center"><strong>Array</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> </tr> <tr> <td style="text-align: center"><strong>Stack</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(1)\)</td> </tr> <tr> <td style="text-align: center"><strong>Queue</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(1)\)</td> </tr> <tr> <td style="text-align: center"><strong>Single Linked List</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(1)\)</td> </tr> <tr> <td style="text-align: center"><strong>Double Linked List</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(1)\)</td> </tr> <tr> <td style="text-align: center"><strong>Hash Table</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">N/A</td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(1)\)</td> </tr> <tr> <td style="text-align: center"><strong>BST</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> </tr> </tbody> </table> <h3 id="search-algorithm">Search Algorithm</h3> <table> <thead> <tr> <th style="text-align: center">Search<br/>Algorithms</th> <th style="text-align: center">Space<br/>Complexity</th> <th style="text-align: center">Time<br/>Complexity</th> <th style="text-align: center"> </th> <th style="text-align: center"> </th> </tr> </thead> <tbody> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td style="text-align: center">Best Case</td> <td style="text-align: center">Average Case</td> <td style="text-align: center">Worst Case</td> </tr> <tr> <td style="text-align: center"><strong>Linear Search</strong></td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> </tr> <tr> <td style="text-align: center"><strong>Binary search</strong></td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> </tr> </tbody> </table> <h3 id="sorting-algorithm">Sorting Algorithm</h3> <table> <thead> <tr> <th style="text-align: center">Sorting<br/>Algorithms</th> <th style="text-align: center">Space<br/>Complexity</th> <th style="text-align: center">Time<br/>Complexity</th> <th style="text-align: center"> </th> <th style="text-align: center"> </th> </tr> </thead> <tbody> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td style="text-align: center">Best Case</td> <td style="text-align: center">Average Case</td> <td style="text-align: center">Worst Case</td> </tr> <tr> <td style="text-align: center"><strong>Selection Sort</strong></td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(n^2)\)</td> <td style="text-align: center">\(O(n^2)\)</td> <td style="text-align: center">\(vO(n^2)\)</td> </tr> <tr> <td style="text-align: center"><strong>Insertion Sort</strong></td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n^2)\)</td> <td style="text-align: center">\(O(n^2)\)</td> </tr> <tr> <td style="text-align: center"><strong>Bubble Sort</strong></td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n^2)\)</td> <td style="text-align: center">\(O(n^2)\)</td> </tr> <tr> <td style="text-align: center"><strong>Quick Sort</strong></td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> </tr> <tr> <td style="text-align: center"><strong>Merge Sort</strong></td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(n)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> </tr> <tr> <td style="text-align: center"><strong>Heap Sort</strong></td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(1)\)</td> <td style="text-align: center">\(O(logn)\)</td> <td style="text-align: center">\(O(logn)\)</td> </tr> </tbody> </table> <p><br/></p> <h1 id="reference">Reference</h1> <ul> <li>CS 430, Introduction to Algorithm, prof. Wang, Xiaolang, Spring 2023, Illinois Institute of Technology</li> <li>Design and analysis of algorithms (2022) GeeksforGeeks. GeeksforGeeks. Available at: <a href="https://www.geeksforgeeks.org/design-and-analysis-of-algorithms/">geeksforgeeks</a>.</li> <li>Team, G.L. (2022) What is time complexity and why is it essential?, Great Learning Blog: Free Resources what Matters to shape your Career! Available at: <a href="https://www.mygreatlearning.com/blog/why-is-time-complexity-essential/">mygreatlearning.com</a>.</li> <li>Dineshpathak, A. (2022) Algorithmic complexity, Devopedia. Devopedia Foundation. Available at: <a href="https://devopedia.org/algorithmic-complexity"> devopedia.org</a>.</li> </ul>]]></content><author><name></name></author><category term="Time_Complexity"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of Growth of Function]]></summary></entry><entry><title type="html">Algorithm &amp;amp; Time Complexity</title><link href="https://namdarine.github.io/blog/2023/Algorithm-Time-complexity/" rel="alternate" type="text/html" title="Algorithm &amp;amp; Time Complexity"/><published>2023-01-20T18:00:00+00:00</published><updated>2023-01-20T18:00:00+00:00</updated><id>https://namdarine.github.io/blog/2023/Algorithm-Time-complexity</id><content type="html" xml:base="https://namdarine.github.io/blog/2023/Algorithm-Time-complexity/"><![CDATA[<p>An algorithm is a finite sequence of precise instructions for performing a computation or for solving a problem. Also, the algorithm is any well-defined computational procedure that takes some values, or set of values, as input and produces some value, or set of values, as output. Thus, a sequence of computational steps transforms the input into the output.</p> <h1 id="properties-of-algorithms">Properties of Algorithms</h1> <ul> <li><strong>Input</strong>: An algorithm has input values from a specified set.</li> <li><strong>Output</strong>: From each set of input values an algorithm produces output values from a specified set. The output values are the solution to the problem.</li> <li><strong>Definiteness</strong>: The steps of an algorithm must be defined precisely.</li> <li><strong>Correctness</strong>: An algorithm should produce the correct output values for each set of input values.</li> <li><strong>Finiteness</strong>: An algorithm should produce the desired output after a finite (but perhaps large) number of steps for any input in the set.</li> <li><strong>Effectiveness</strong>: It must be possible to perform each step of an algorithm exactly and in a finite amount of time.</li> <li><strong>Generality</strong>: The procedure should be applicable for all problems of the desired form, not just for a particular set of input values.</li> </ul> <h1 id="what-is-meant-by-algorithm-analysis">What is meant by Algorithm Analysis?</h1> <p>Algorithm analysis is an important part of computational complexity theory, which provides theoretical estimation for the required resources of an algorithm to solve a specific computational problem. So, the analysis of algorithms determines the amount of time and space resources required to execute the algorithm.</p> <h2 id="why-analysis-of-algorithms-is-important">Why Analysis of Algorithms is IMPORTANT?</h2> <ul> <li>To predict the behavior of an algorithm without implementing it on a specific computer.</li> <li>It is much more convenient to have simple measures for the efficiency of an algorithm than to implement the algorithm and test the efficiency every time a certain parameter in the underlying computer system changes.</li> <li>It is impossible to predict the exact behavior of an algorithm. There are too many influencing factors.</li> <li>The analysis is thus only an approximation; it is not perfect.</li> <li>More importantly, by analyzing different algorithms, we can compare them to determine the best one for our purpose.</li> </ul> <h1 id="complexity-of-algorithm">Complexity of Algorithm</h1> <p>To analyze the efficacy of an algorithm, usually consider two measurements: <strong>time</strong> and <strong>memory needed</strong>. An analysis of the time required to solve a problem of a particular size involves the <strong>time complexity</strong> of the algorithm. An analysis of the computer memory required involves the <strong>space complexity</strong> of the algorithm.</p> <h2 id="time-complexity">Time Complexity</h2> <blockquote> <p>The amount of time taken by an algorithm to run, as a function of the length of the input. It measures the time taken to execute each statement of code in an algorithm.</p> </blockquote> <p>The time complexity of an algorithm can be expressed in terms of the number of operations used by the algorithm when the input has a particular size.</p> <h3 id="time-complexity-is-significant">Time complexity is significant</h3> <p>An algorithm is a finite sequence of well-defined instructions, typically executed in a computer, to solve a class of problems or to perform a common task. We also indicated the algorithm to be performed in a computer, which leads to the next variation, in terms of the operating system, processor, hardware, etc. that are used which can also influence the way an algorithm can be performed.</p> <h1 id="reference">Reference</h1> <ul> <li> <p>CS 430, Introduction to Algorithms, Spring 2023, prof. Xiaolang Wang, Illinois Institute of Technology</p> </li> <li> <p>Design and analysis of algorithms (2022) GeeksforGeeks. GeeksforGeeks. Available at: <a href="https://www.geeksforgeeks.org/design-and-analysis-of-algorithms/">geeksforgeeks</a> (Accessed: January 19, 2023).</p> </li> <li> <p>Dineshpathak, A. (2022) Algorithmic complexity, Devopedia. Devopedia Foundation. Available at: <a href="https://devopedia.org/algorithmic-complexity#:~:text=Algorithmic">devopedia</a> complexity is a measure,asymptotically as n approaches infinity. (Accessed: January 19, 2023).</p> </li> </ul>]]></content><author><name></name></author><category term="Algorithm"/><category term="WIL"/><summary type="html"><![CDATA[Concepts and understanding of Algorithm and Time complexity]]></summary></entry></feed>